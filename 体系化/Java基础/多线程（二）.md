### 概念整理

锁类型：显示锁、可重入锁、公平锁、非公平锁

> - ReentrantLock属于显示锁，实现Lock接口，需要自己调用lock，unlock
> - 可重入锁，ReentrantLock和Synchronized都是可重入锁，就是在拿到锁的时候，同步代码块中可以再次对锁对象进行加锁
> - 公平锁/非公平锁，Synchronized为非公平锁，ReentrantLock支持设置是否为公平锁或者非公平锁

锁状态：无锁、偏向锁、轻量锁、重量锁

> 其实是对 Synchronized的优化，根据不同的竞争情况，对锁状态一步步膨胀

锁实现方式：继承AQS、CAS、Synchronized



### 一、启动方式

启动方式只有两种：

1. X extends Thread，然后X.start()
2. X implements Runable，然后交给Thread运行

Callable方式其实内部也是Runable的方式，先创建Callable，然后讲它丢给FutureTask，然后再把FutureTask给Thread运行。FutureTask继承Runable，内部只是对Callable的返回值做了保存，方便获取。

### 二、线程的状态

java中的线程状态分为6种：

1. 初始（new）：新创建了一个线程对象，但是没有调用start方法。
2. 运行（runnable）：java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。线程对象创建后，其他线程（比如main线程）调用了该对象的start方法，该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。
3. 阻塞（blocked）：表示线程阻塞于锁。
4. 等待（waiting）：进入该状态的线程需要等待其他线程作出一些特定动作（通知或中断）。
5. 超时等待（timed_waiting）：该状态不同于waiting，它可以在指定的时间后自行返回。
6. 终止（terminated）：表示该线程已经执行完毕。

状态之间的变迁如下图所示：

<img src="/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309103003788.png" alt="image-20220309103003788" style="zoom:50%;" />



### 三、死锁

#### 概念

是指两个或两个以上的线程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若**无外力作用**，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。

举个例子：A和B去按摩洗脚，都想在洗脚的时候，同时顺便做个头部按摩，13技师擅长足底按摩，14技师擅长头部按摩。这个时候A先抢到了14，B先抢到了13，两个人都想同时洗脚和头部按摩，于是互不相让，扬言我死也不让你，这样的话，A抢到了14， 想要13；B抢到了13，想要14，在这个想同时洗脚和头部按摩的事情上A和B就产生了死锁。怎么解决这个问题呢？

第一种，假如这个时候，来了个15，刚好也擅长头部按摩，A又没有两个脑袋，自然就归了B，于是B就美滋滋的洗脚和头部按摩，剩下的A在旁边气鼓鼓的，这个时候死锁这种情况就被打破了，不存在了。

第二种，C出场了，用武力强迫A和B，必须先做洗脚，再头部按摩，这种情况下，A和B谁先抢到13，谁就可以进行下去，另外一个没抢到的，就等着，这种情况下，也不会产生死锁。

总结一下：
死锁是必然发生在多操作者（M>=2个）情况下，争夺多个资源（N>=2个，且N<=M）才会发生这种情况。很明显，单线程自然不会有死锁，只有B一个人去，不要2个，打十个都没问题。单资源呢？只有13，A和B也只会产生激烈的竞争，打得不可开交，谁抢到就是谁的，但不会产生死锁。同时，死锁还有几个要求：
1. 争夺资源的顺序不对，如果争夺资源的顺序一样的，也不会产生死锁；
2. 争夺者拿到资源不放松。

#### 学术化的定义

死锁的发生必须具备以下四个必要条件：
1. **互斥条件**：指线程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个线程占用。如果此时还有其他线程请求资源，则请求者只能等待，直到占有资源的线程用完释放。
2. **请求和保持条件**：指线程已经保持至少一个资源，但又提出了新的资源的请求，而该资源已被其他线程占有，此时请求线程阻塞，但又对自己已获得的其他资源保持不放。
3. **不剥夺条件**：指线程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
4. **环路等待条件**：指在发生死锁时，必然存在一个线程——资源的环形链，即线程集合{p0，p1，p2......pn}中的p0正在等待一个p1占用的资源；p1正在等待p2占用的资源，...pn正在等待已被p0占用的资源。

理解了死锁的原因，尤其是产生死锁的四大必要条件，就可以最大可能的避免、预防和解除死锁。只要打破四大必要条件之一就能有效预防死锁的发生。
1. 打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。
2. 打破不可抢占条件：当一线程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。
3. 打破占有且申请条件：采用资源预先分配策略，即线程运行钱申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。
4. 打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有线程只能采用按序号递增的形式申请资源。

避免死锁常见的算法有有序资源分配法、银行家算法。

#### 危害
1. 线程不工作了，但是整个程序还是活着的。
2. 没有任何的异常信息可以供我们检查。
3. 一旦程序发生了死锁，是没有任何的办法恢复的，只能重启程序，对正式已发布程序来说，这是个很严重的问题。

#### 解决
关键是保证拿锁的顺序一致，两种解决方案：
1. 内部通过顺序比较，确定拿锁的顺序；
2. 采用尝试拿锁的机制。

### 四、其他线程安全问题

#### 活锁
两个线程在尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生同一个线程总是拿到同一把锁，在尝试拿另一把锁时因为拿不到，而将本来已经持有的锁释放的过程。
解决办法：每个线程休眠随机数，错开拿锁的时间。

#### 线程饥饿
低优先级的线程，总是拿不到执行时间。

### 五、ThreadLocal辨析
#### 与与Synchronized的比较
ThreadLocal和Synchronized都用于解决多线程并发访问。可是ThreadLocal与Synchronized有本质的差别。Synchronized是利用锁的机制，而变量或代码块在某一时刻仅仅能被一个线程访问。而ThreadLocal为每个线程都提供了变量副本，使得每个线程在某一时间访问到的并非同一个对象，这样就隔离了多个线程对数据的共享。

#### ThreadLocal的使用
ThreadLocal类接口很简单，只有4个方法，我们先来了解一下：
- void set(Object value)   //设置当前线程的线程局部变量的值
- public Object get()  //该方法返回当前线程所对应的线程局部变量
- public void remove()  //将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK5.0新增。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显示调用该方法清除线程的局部变量并不是必要的操作，但它可以加快内存回收的速度。
- protected Object initialValue()  //返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。

```java
public final static ThreadLocal<String> resource = new ThreadLocal<String>;
```

resource代表一个能存放String类型的ThreadLocal对象。此时不论什么一个线程能够并发访问这个变量，对它进行写入、读取都是线程安全的。

#### 实现解析

<img src="/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309134258414.png" alt="image-20220309134258414" style="zoom:80%;" />

<img src="/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309134346116.png" alt="image-20220309134346116" style="zoom:67%;" />

```java
public T get(){
  Thread t = Thread.currentThread();
  ThreadLocalMap map = getMap(t);
  if(map != null){
    ThreadLocalMap.Entry e = map.getEntry(this);
    if(e != null){
      T result = (T)e.value;
      return result;
    }
  }
  return setInitialValue();
}

ThreadLocalMap getMap(Thread t){
  return t.threadLocals;
}

//Thread.java
class Thread{
  ThreadLocal.ThreadLocalMap threadLocals = null;
}
```

上面先取到当前线程，然后调用getMap方法获取对应的ThreadLocalMap，ThreadLocalMap是ThreadLocal的静态内部类，然后Thread类中有一个这样的类型成员，所以getMap是直接返回Thread的成员。

看下ThreadLocal的内部类ThreadLocalMap源码：

<img src="/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309142359028.png" alt="image-20220309142359028" style="zoom:67%;" />

可以看到有个Entry内部静态类，它继承了WeakReference，总之它记录了两个信息，一个是ThreadLocal<?>类型，一个是Object类型的值，getEntry方法则是获取某个ThreadLocal对应的值，set方法就是更新或赋值相应的ThreadLocal对应的值。

回顾我们的get方法，其实就是拿到每个线程独有的ThreadLocalMap，然后再用ThreadLocal的当前实例，拿到Map中的相应的Entry，然后就可以拿到相应的值返回出去。当然，如果Map为空，还会先进行map的创建，初始化等工作。

 ### 六、 CAS基本原理

#### 什么是原子操作？如何实现原子操作？

假如有两个操作A和B（A和B可能都很复杂），如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。

实现原子操作可以使用锁，锁机制，满足基本的需求是没有问题的了，但是有的时候我们的需求并非这么简单，我们需要更有效，更加灵活的机制，synchronized关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待，直到该线程释放锁。这里会有些问题：首先，如果被阻塞的线程优先级很高很重要怎么办？其次，如果获得锁的线程一直不释放锁怎么办？（这种情况是非常糟糕的）。还有一种情况，如果有大量的线程来竞争资源，那CPU将会花费大量的时间和资源来处理这些竞争，同时，还有可能出现一些例如死锁之类的情况，最后，其实锁机制是一种比较粗糙，粒度比较大的机制，相对于像计数器这样的需求有点儿过于笨重。

实现原子操作还可以使用当前的处理器基本都支持CAS()的指令，只不过每个厂家所实现的算法并不一样，每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。CAS的基本思路就是，如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事儿，但是要返回原值是多少。循环CAS就是在一个循环里不断的做cas操作，直到成功为止。

<img src="/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309143744332.png" alt="image-20220309143744332" style="zoom:50%;" />

####  CAS实现原子操作的三大问题

##### 1、ABA问题

因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。

ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。举个通俗点的例子，你倒了一杯水放桌子上，干了点别的事，然后同事把你水喝了又给你重新倒了一杯水，你回来看水还在，拿起来就喝，如果你不管水中间被人喝过，只关心水还在，这就是ABA问题。

如果你是一个讲卫生讲文明的小伙子，不但关心水在不在，还要在你离开的时候水被人动过没有，因为你是程序员，所以就想起了放了张纸在旁边，写上初始值0，别人喝水前麻烦先做个累加才能喝水。

##### 2、循坏时间长开销大

自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。

##### 3、只能保证一个共享变量的原子操作

当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。

#### JDK中相关原子操作类的使用

##### AtomicInteger

- int addAndGet（int delta）：以原子方式将输入的数值与实例中的值 

  （AtomicInteger 里的 value）相加，并返回结果。

- boolean compareAndSet（int expect，int update）：如果输入的数值等 

  于预期值，则以原子方式将该值设置为输入的值。

- int getAndIncrement()：以原子方式将当前值加 1，注意，这里返回的是自 

  增前的值。

- int getAndSet（int newValue）：以原子方式设置为 newValue 的值，并返 

  回旧值。

##### AtomicIntegerArray

主要是提供原子的方式更新数组里的整型，其常用方法如下:

- int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引 i 的 

  元素相加。

- boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。

  需要注意的是，数组value通过构造方法传递进去，然后AtomicIntegerArray会将当前数组复制一份，所以当AtomicIntegerArray对内部的数组元素进行修改时，不会影响传入的数组。

##### 更新引用类型

原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。

###### AtomicReference

原子更新引用类型

###### AtomicStampedReference

利用版本戳的形式记录了每次改变以后的版本号，这样的话就不会存在ABA问题了。这就是AtomicStampedReference的解决方案。AtomicMarkableReference跟AtomicStampedReference差不多， AtomicStampedReference是使用pair的int stamp作为计数器使用，AtomicMarkableReference的pair使用的是boolean mark。 还是那个水的例子，AtomicStampedReference可能关心的是动过几次，AtomicMarkableReference关心的是有没有被人动过，方法都比较简单。

###### AtomicMarkableReference

原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference（V initialRef，booleaninitialMark）

### 七、阻塞队列和线程池原理

#### 阻塞队列

<img src="/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309151251443.png" alt="image-20220309151251443" style="zoom:67%;" />

队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。

在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能最先从队列中删除，故队列又称为先进先出（FIFO—first in first out）线性表。

##### 什么是阻塞队列

1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。

2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。

在并发编程中使用**生产者和消费者模式**能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。

在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。

为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。

阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。

![image-20220309151752033](/Users/liujian/Documents/study/books/AndroidStudy/图片/image-20220309151752033.png)

- 抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（"Queuefull"）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。
- 返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。
- 一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。
- 超时退出：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。

##### 常用阻塞队列

- ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。
- LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列
- PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。
- DelayQueue：一个使用优先级队列实现的无界阻塞队列。
- SynchronousQueue：一个不存储元素的阻塞队列。
- LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
- LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

以上的阻塞队列都实现了BlockingQueue接口，也都是线程安全的。

###### 有界无界？

有限队列就是长度有限，满了以后生产者会阻塞，无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，当然空间限制来源于系统资源的限制，如果处理不及时，导致队列越来越大越来越大，超出一定的限制致使内存超限，操作系统或者JVM帮你解决烦恼，直接把你 OOM kill 省事了。

无界也会阻塞，为何？因为阻塞不仅仅体现在生产者放入元素时会阻塞，消费者拿取元素时，如果没有元素，同样也会阻塞。

###### ArrayBlockingQueue

是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证线程公平的访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非公平性是对先等待的线程是非公平的，当队列可用时，阻塞的线程都可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。初始化时有参数可以设置。

###### LinkedBlockingQueue

是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序。

###### Array实现和Linked实现的区别

1. 队列中锁的实现不同

   ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；

   LinkedBlockingQueue实现的队列中的锁是分离的，即生产用的是putLock，消费是takeLock

2. 在生产或消费时操作不同

   ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的；

   LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node<E>进行插入或移除，会影响性能

3. 队列大小初始化方式不同

   ArrayBlockingQueue实现的队列中必须指定队列的大小；

   LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE

###### PriorityBlockingQueue

PriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。

###### DelayQueue

是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。

DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。

缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。

###### SynchronousQueue

是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合传递性场景。

###### LinkedTransferQueue

多了tryTransfer和transfer方法，

（1）transfer方法

如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。

（2）tryTransfer方法

tryTransfer方法是用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法是必须等到消费者消费了才返回。

###### LinkedBlockingDeque

LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列指的是可以从队列的两端插入和移出元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。

多了addFirst、addLast、offerFirst、offerLast、peekFirst和peekLast等方法，以First单词结尾的方法，表示插入、获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入、获取或移除双端队列的最后一个元素。另外，插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是JDK的bug，使用时还是用带有First和Last后缀的方法更清楚。在初始化LinkedBlockingDeque时可以设置容量防止其过度膨胀。另外，双向阻塞队列可以运用在“工作窃取”模式中。

#### 线程池

##### 为什么要用线程池？

Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。在开发过程中，合理地使用线程池能够带来3个好处。

第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。  如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务器性能。线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。

第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。

